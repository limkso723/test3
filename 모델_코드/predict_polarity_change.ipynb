{"cells":[{"cell_type":"markdown","metadata":{"id":"jprcZhTyetFF"},"source":["# 모듈 import 및 전역 변수 설정"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sCpiZEmLODWo","executionInfo":{"status":"ok","timestamp":1667968727124,"user_tz":-540,"elapsed":16784,"user":{"displayName":"Python Team","userId":"00791902300481953740"}},"outputId":"91ad3de1-de27-4410-94b4-e6fd9581d297"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"id":"kz4nh9S0I1uM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667968737841,"user_tz":-540,"elapsed":10722,"user":{"displayName":"Python Team","userId":"00791902300481953740"}},"outputId":"30a882ee-2a23-4018-e98e-c1078f35bdb9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 4.9 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 39.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 48.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n"]}]},{"cell_type":"code","source":["pip install datasets"],"metadata":{"id":"_SVYWZE5I1e0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667968745400,"user_tz":-540,"elapsed":7572,"user":{"displayName":"Python Team","userId":"00791902300481953740"}},"outputId":"12b058e8-a1a1-49be-83d3-f49aa0c04fb0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n","\u001b[K     |████████████████████████████████| 441 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting dill<0.3.6\n","  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n","\u001b[K     |████████████████████████████████| 95 kB 2.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 47.6 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 61.4 MB/s \n","\u001b[?25hRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 30.9 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 47.0 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, dill, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.6\n","    Uninstalling dill-0.3.6:\n","      Successfully uninstalled dill-0.3.6\n","Successfully installed datasets-2.6.1 dill-0.3.5.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"8LDwADWNMpsC","executionInfo":{"status":"ok","timestamp":1667968753278,"user_tz":-540,"elapsed":7883,"user":{"displayName":"Python Team","userId":"00791902300481953740"}}},"outputs":[],"source":["import json\n","import os\n","\n","import torch\n","import torch.nn as nn\n","from tqdm import trange\n","from transformers import AutoModel, AutoTokenizer\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import AdamW\n","from datasets import load_metric\n","from sklearn.metrics import f1_score\n","import pandas as pd\n","import copy\n","\n","PADDING_TOKEN = 1\n","S_OPEN_TOKEN = 0\n","S_CLOSE_TOKEN = 2\n","\n","do_eval=True\n","\n","max_len = 256\n","batch_size = 8\n","base_model = 'kykim/electra-kor-base'\n","learning_rate = 3e-6\n","eps = 1e-8\n","num_train_epochs = 60\n","classifier_hidden_size = 768\n","classifier_dropout_prob = 0.1\n","\n","polarity_id_to_name = ['positive', 'negative', 'neutral']\n","polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","special_tokens_dict = {\n","    'additional_special_tokens': ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n","}"]},{"cell_type":"markdown","metadata":{"id":"xGmH15hCeqhJ"},"source":["json 및 jsonl 파일 read, write 함수"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6vGeHU4yP2Sg","executionInfo":{"status":"ok","timestamp":1667968753279,"user_tz":-540,"elapsed":18,"user":{"displayName":"Python Team","userId":"00791902300481953740"}}},"outputs":[],"source":["def jsonload(fname, encoding=\"utf-8\"):\n","    with open(fname, encoding=encoding) as f:\n","        j = json.load(f)\n","\n","    return j\n","\n","# json 개체를 파일이름으로 깔끔하게 저장\n","def jsondump(j, fname):\n","    with open(fname, \"w\", encoding=\"UTF8\") as f:\n","        json.dump(j, f, ensure_ascii=False)\n","\n","# jsonl 파일 읽어서 list에 저장\n","def jsonlload(fname, encoding=\"utf-8\"):\n","    json_list = []\n","    with open(fname, encoding=encoding) as f:\n","        for line in f.readlines():\n","            json_list.append(json.loads(line))\n","    return json_list\n","\n","# jsonlload('D:\\새 폴더\\PythonWork\\korean_ABSA_baseline-main\\nikluge-sa-2022-train.jsonl')"]},{"cell_type":"markdown","metadata":{"id":"xuHV8HGqXvg_"},"source":["# 모델 정의\n","xlm-roberta 모델을 기반으로 한 classification 모델 이용"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"WkyrAEhAQBQV","executionInfo":{"status":"ok","timestamp":1667970819650,"user_tz":-540,"elapsed":377,"user":{"displayName":"Python Team","userId":"00791902300481953740"}}},"outputs":[],"source":["class SimpleClassifier(nn.Module):\n","\n","    def __init__(self, num_label):\n","        super().__init__()\n","        self.dense = nn.Linear(classifier_hidden_size, classifier_hidden_size)\n","        self.dropout = nn.Dropout(classifier_dropout_prob)\n","        self.output = nn.Linear(classifier_hidden_size, num_label)\n","\n","    def forward(self, features):\n","        x = features[:, 0, :]\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = torch.tanh(x)\n","        x = self.dropout(x)\n","        x = self.output(x)\n","        return x\n","\n","\n","class RoBertaBaseClassifier(nn.Module):\n","    def __init__(self, num_label, len_tokenizer):\n","        super(RoBertaBaseClassifier, self).__init__()\n","\n","        self.num_label = num_label\n","        self.xlm_roberta = AutoModel.from_pretrained(base_model)\n","        self.xlm_roberta.resize_token_embeddings(len_tokenizer)\n","\n","        self.labels_classifier = SimpleClassifier(self.num_label)\n","\n","    def forward(self, input_ids, attention_mask, labels=None):\n","        outputs = self.xlm_roberta(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=None\n","        )\n","\n","        sequence_output = outputs[0]\n","        logits = self.labels_classifier(sequence_output)\n","\n","        loss = None\n","\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.num_label),\n","                                                labels.view(-1))\n","\n","        return loss, logits\n"]},{"cell_type":"markdown","metadata":{"id":"VTLJM3T2jEse"},"source":["# 모델 평가"]},{"cell_type":"markdown","metadata":{"id":"5YqSiRaPjF-z"},"source":["학습된 모델을 바탕으로 국어원 데이터 형태를 만드는 방법 예시"]},{"cell_type":"markdown","metadata":{"id":"fpQwoVahjZoV"},"source":["테스트 데이터에 대한 평가"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HweLC61PIvyj"},"outputs":[],"source":["import re"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RCF_xspZIvyj"},"outputs":[],"source":["# 감성만 바꿔주는 def\n","def predict_from_korean_form(tokenizer, pc_model, data):\n","    for sentence in data:\n","        \n","        form = sentence['sentence_form']\n","        # form = re.sub(\"[.]\",'',form)\n","        entity = sentence['annotation']\n","        sentence['annotation'] = []\n","        for i in entity:\n","            tokenized_data = tokenizer(form, i[0], padding='max_length', max_length=256, truncation=True)\n","\n","            input_ids = torch.tensor([tokenized_data['input_ids']]).to(device)\n","            attention_mask = torch.tensor([tokenized_data['attention_mask']]).to(device)\n","\n","            with torch.no_grad():\n","                _, pc_logits = pc_model(input_ids, attention_mask)\n","\n","            pc_predictions = torch.argmax(pc_logits, dim=-1)\n","            pc_result = polarity_id_to_name[pc_predictions[0]]\n","\n","            sentence['annotation'].append([i[0], pc_result])\n","\n","    return data"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"vA-I57j1Ivyj","executionInfo":{"status":"ok","timestamp":1667969392862,"user_tz":-540,"elapsed":2,"user":{"displayName":"Python Team","userId":"00791902300481953740"}}},"outputs":[],"source":["# 바꿔줄 pred_data파일 경로 설정\n","test_data_path = '/content/drive/MyDrive/메인프로젝트(5조)/말뭉치 경진대회/H.O.F/11_07/entity_ensemble/11.07_63.89+high_single_1_3_2.json'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gor_yntkIvyj"},"outputs":[],"source":["def test_sentiment_analysis_save():\n","    # polarity pt 파일 경로 설정\n","    test_polarity_classification_model_path = '/content/drive/MyDrive/메인프로젝트(5조)/말뭉치 경진대회/data_train_dev_polarity_ver.2/saved_model_epoch_7.pt'\n","    tokenizer = AutoTokenizer.from_pretrained(base_model)\n","    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n","    test_data = jsonload(test_data_path)\n","            \n","    polarity_model = RoBertaBaseClassifier(len(polarity_id_to_name), len(tokenizer))\n","    polarity_model.load_state_dict(torch.load(test_polarity_classification_model_path, map_location=device))\n","    polarity_model.to(device)\n","    polarity_model.eval()\n","\n","    pred_data = predict_from_korean_form(tokenizer, polarity_model, copy.deepcopy(test_data))\n","\n","    jsondump(pred_data, '/content/drive/MyDrive/메인프로젝트(5조)/말뭉치 경진대회/H.O.F/11_08/최고점_갱신_63.90/11.07_63.89+high_single_132_polarity_change_data_7.json')\n","    # pred_data = jsonload('C:\\\\Users\\A\\OneDrive\\바탕 화면\\PythonWork\\korean_ABSA_baseline-main\\H.O.F\\\\11.03_하이스코어\\pred_data_병진스페셜_13.json')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5vjQ_rlrIvyk","outputId":"9d160c4e-2336-4080-d233-dee931af3c4a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667891903668,"user_tz":-540,"elapsed":50020,"user":{"displayName":"Python Team","userId":"00791902300481953740"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at kykim/electra-kor-base were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n","- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["test_sentiment_analysis_save()"]},{"cell_type":"code","source":[],"metadata":{"id":"oZ9GP-i8sRL3"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 ('test')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"8d9cd5405d0ea994988d9a1870a24bed550406ecac442e5d6c65a056768d87d5"}},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}